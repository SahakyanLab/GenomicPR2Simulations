?mode
runApp("~/Documents/ISM/", launch.browser = T)
runApp("~/Documents/ISM/", launch.browser = T)
runApp("~/Documents/ISM/", launch.browser = T)
runApp("~/Documents/ISM/", launch.browser = T)
library(shiny)
runApp("~/Documents/ISM/", launch.browser = T)
runApp("~/Documents/ISM/", launch.browser = T)
runApp("~/Documents/ISM/", launch.browser = T)
runApp("~/Documents/ISM/", launch.browser = T)
runApp("~/Documents/ISM/", launch.browser = T)
runApp("~/Documents/ISM/", launch.browser = T)
runApp("~/Documents/ISM/", launch.browser = T)
runApp("~/Documents/ISM/", launch.browser = T)
runApp("~/Documents/ISM/", launch.browser = T)
runApp("~/Documents/ISM/", launch.browser = T)
runApp("~/Documents/ISM/", launch.browser = T)
runApp("~/Documents/ISM/", launch.browser = T)
runApp("~/Documents/ISM/", launch.browser = T)
runApp("~/Documents/ISM/", launch.browser = T)
runApp("~/Documents/ISM/", launch.browser = T)
runApp("~/Documents/ISM/", launch.browser = T)
runApp("~/Documents/ISM/", launch.browser = T)
runApp("~/Documents/ISM/", launch.browser = T)
runApp("~/Documents/ISM/", launch.browser = T)
library("rJava")
library("rJava")
.jinit(classpath="igvtool.jar")
.jinit(classpath="~/miniconda3/share/igvtools-2.3.93-0/igvtools.jar")
library("rJava")
.jinit(classpath="igvtool.jar")
library(Biostrings)
reverseComplement(DNAStringSet("kca"))
reverseComplement(DNAStringSet("ca"))
reverseComplement(DNAStringSet("kga"))
reverseComplement(DNAStringSet("ga"))
reverseComplement(DNAStringSet("ta"))
reverseComplement(DNAStringSet("ga"))
reverseComplement(DNAStringSet("ca"))
0.8/10
0.1/0.8
1/0.8
0.9/0.8
0.10.8
0.1/0.8
# random data set generation
set.seed(seed = 1234)
df <- data.frame(x = rnorm(n = 100, mean = 10, sd = 1),
y = rnorm(n = 100, mean = 40, sd = 1))
plot(df)
df <- data.frame(x = runif(n = 100, mean = 10, sd = 1),
y = runif(n = 100, mean = 40, sd = 1))
df <- data.frame(x = runif(n = 100, min = 10, max = 15),
y = runif(n = 100, min = 35, max = 50))
plot(df)
set.seed(seed = 1)
x1 <- runif(n = num.points, min = lower.bound, max = upper.bound)
# random data set generation
m <- 1
b <- 0
lower.bound <- -25
upper.bound <- 25
num.points <- 100
set.seed(seed = 1)
x1 <- runif(n = num.points, min = lower.bound, max = upper.bound)
set.seed(seed = 1234)
x1 <- runif(n = num.points, min = lower.bound, max = upper.bound)
x1
x2
# random data set generation
m <- 1
b <- 0
lower.bound <- -25
upper.bound <- 25
num.points <- 100
set.seed(seed = 1)
x1 <- runif(n = num.points, min = lower.bound, max = upper.bound)
set.seed(seed = 1234)
x2 <- runif(n = num.points, min = lower.bound, max = upper.bound)
n <- c(200,200)                 # Number of points in each class
cls <- rep(1:2, n)              # Class memberships
i <- c(.2-.12*abs(rnorm(n[1])), # Noiseless x position
-.2+.12*abs(rnorm(n[2])))
noise <- .04*(.2-abs(i))        # Noise level relative to `i`
# Final sample
x <- cbind(i, abs(.5*i)) + noise*matrix(rnorm(sum(n)*2), sum(n), 2)
plot(x[,1], x[,2], col=cls)
cls
# Number of points in each class
n <- c(100, 100)
cls <- rep(1:2, n)              # Class memberships
cls
rnorm(n[1])
n
abs(rnorm(n[1])
abs(rnorm(n[1]))
range(abs(rnorm(n[1])))
plot(.2-.12*abs(rnorm(n[1]))
plot(.2-.12*abs(rnorm(n[1])))
i <- c(.2-.12*abs(rnorm(n[1])), -.2+.12*abs(rnorm(n[2])))
noise <- .04*(.2-abs(i))        # Noise level relative to `i`
noise
noise <- .4*(.2-abs(i))        # Noise level relative to `i`
# Final sample
x <- cbind(i, abs(.5*i)) + noise*matrix(rnorm(sum(n)*2), sum(n), 2)
plot(x[,1], x[,2], col=cls)
# Number of points in each class
n <- 100
cls <- rep(1, n)              # Class memberships
i <- c(.2-.12*abs(rnorm(n[1])))
noise <- .4*(.2-abs(i))        # Noise level relative to `i`
# Final sample
x <- cbind(i, abs(.5*i)) + noise*matrix(rnorm(sum(n)*2), sum(n), 2)
plot(x[,1], x[,2], col=cls)
# Number of points in each class
n <- 100
cls <- rep(1, n)              # Class memberships
i <- c(.2-.12*abs(rnorm(n[1])))
noise <- .04*(.2-abs(i))        # Noise level relative to `i`
# Final sample
x <- cbind(i, abs(.5*i)) + noise*matrix(rnorm(sum(n)*2), sum(n), 2)
plot(x[,1], x[,2], col=cls)
noise <- .1*(.2-abs(i))        # Noise level relative to `i`
# Final sample
x <- cbind(i, abs(.5*i)) + noise*matrix(rnorm(sum(n)*2), sum(n), 2)
plot(x[,1], x[,2], col=cls)
# Number of points in each class
n <- 100
cls <- rep(1, n)              # Class memberships
i <- c(.2-.12*abs(rnorm(n[1])))
noise <- .1*(.2-abs(i))        # Noise level relative to `i`
# Final sample
x <- cbind(i, abs(.5*i)) + noise*matrix(rnorm(sum(n)*2), sum(n), 2)
plot(x[,1], x[,2], col=cls)
# random data set generation
n <- 10
cls <- rep(1, n)
i <- c(.2-.12*abs(rnorm(n[1])))
noise <- .1*(.2-abs(i))
# Final sample
x <- cbind(i, abs(.5*i)) + noise*matrix(rnorm(sum(n)*2), sum(n), 2)
plot(x[,1], x[,2], col=cls)
# random data set generation
n <- 100
cls <- rep(1, n)
i <- c(.2-.12*abs(rnorm(n[1])))
noise <- .1*(.2-abs(i))
# Final sample
x <- cbind(i, abs(.5*i)) + noise*matrix(rnorm(sum(n)*2), sum(n), 2)
plot(x[,1], x[,2], col=cls)
noise <- .3*(.2-abs(i))
# Final sample
x <- cbind(i, abs(.5*i)) + noise*matrix(rnorm(sum(n)*2), sum(n), 2)
plot(x[,1], x[,2], col=cls)
noise <- .1*(.2-abs(i))
# Final sample
x <- cbind(i, abs(.5*i)) + noise*matrix(rnorm(sum(n)*2), sum(n), 2)
plot(x[,1], x[,2], col=cls)
head(x)
matrix(rnorm(sum(n)*2), sum(n), 2)
head(x)
# Final sample
x <- cbind(radio = i,
ads = abs(.5*i)) + noise*matrix(rnorm(sum(n)*2), sum(n), 2)
head(x)
plot(x)
# cost function
cost.function <- function(radio, ads, weight, bias){
companies <- length(radio)
total.error = 0.0
for(i in 1:length(companies)){
total.error <- total.error + (ads[i] - (weight*radio[x]+bias))**2
}
return(total.error/companies)
}
i=10
i%%10
i=3
i%%10
i=4
i%%10
head(x)
# model evaluation
train(radio = x[,"radio"], ads = x[, "ads"],
weight = 0, bias = 0, learning.rate = 0.1, iters = 100)
# Linear regression from scratch
# random data set generation
n <- 100
cls <- rep(1, n)
i <- c(.2-.12*abs(rnorm(n[1])))
noise <- .1*(.2-abs(i))
# Final sample
x <- cbind(radio = i,
ads = abs(.5*i)) + noise*matrix(rnorm(sum(n)*2), sum(n), 2)
# cost function
cost.function <- function(radio, ads, weight, bias){
companies <- length(radio)
total.error = 0.0
for(i in 1:length(companies)){
total.error <- total.error + (ads[i] - (weight*radio[x]+bias))**2
}
return(total.error/companies)
}
# gradient descent
gradient.descent <- function(radio, ads, weight, bias, learning.rate){
weight.deriv <- 0
bias.deriv <- 0
companies <- length(radio)
for(i in 1:length(companies)){
# calculate partial derivatives
weight.deriv <- weight.deriv + (-2*radio[i]*(ads[i]-weight*radio[i]+bias))
bias.deriv <- bias.deriv + (-2*ads[i]-(weight*radio[i]+bias))
}
# subtract as the derivatives point in the direction of steepest ascent
weight <- weight - (weight.deriv/companies) * learning.rate
bias <- bias - (bias.deriv/companies)*learning.rate
return(list(weight, bias))
}
# model training
train <- function(radio, ads, weight, bias, learning.rate, iters){
cost.history <- numeric()
for(i in 1:length(iters)){
gradient.descent.out <- gradient.descent(radio, ads, weight, bias, learning.rate)
weight <- gradient.descent.out[[1]]
bias <- gradient.descent.out[[2]]
# calculate cost
cost <- cost.function(radio, ads, weight, bias)
cost.history <- c(cost.history, cost)
# Log the progress
if(i%%10 == 0){
print(paste0("iters = ", i, "\t",
"weight = ", weight, "\t",
"bias = ", bias, "\t"))
}
}
return(list(weight, bias, cost.history))
}
# model evaluation
train(radio = x[,"radio"], ads = x[, "ads"],
weight = 0, bias = 0, learning.rate = 0.1, iters = 100)
head(x)
abs(x)
x <- abs(x)
plot(x)
# cost function
cost.function <- function(radio, ads, weight, bias){
companies <- length(radio)
total.error = 0.0
for(i in 1:length(companies)){
total.error <- total.error + (ads[i] - (weight*radio[x]+bias))**2
}
return(total.error/companies)
}
# gradient descent
gradient.descent <- function(radio, ads, weight, bias, learning.rate){
weight.deriv <- 0
bias.deriv <- 0
companies <- length(radio)
for(i in 1:length(companies)){
# calculate partial derivatives
weight.deriv <- weight.deriv + (-2*radio[i]*(ads[i]-weight*radio[i]+bias))
bias.deriv <- bias.deriv + (-2*ads[i]-(weight*radio[i]+bias))
}
# subtract as the derivatives point in the direction of steepest ascent
weight <- weight - (weight.deriv/companies) * learning.rate
bias <- bias - (bias.deriv/companies)*learning.rate
return(list(weight, bias))
}
# model training
train <- function(radio, ads, weight, bias, learning.rate, iters){
cost.history <- numeric()
for(i in 1:length(iters)){
gradient.descent.out <- gradient.descent(radio, ads, weight, bias, learning.rate)
weight <- gradient.descent.out[[1]]
bias <- gradient.descent.out[[2]]
# calculate cost
cost <- cost.function(radio, ads, weight, bias)
cost.history <- c(cost.history, cost)
# Log the progress
if(i%%10 == 0){
print(paste0("iters = ", i, "\t",
"weight = ", weight, "\t",
"bias = ", bias, "\t"))
}
}
return(list(weight, bias, cost.history))
}
# model evaluation
train(radio = x[,"radio"], ads = x[, "ads"],
weight = 0, bias = 0, learning.rate = 0.1, iters = 100)
# model evaluation
train(radio = x[,"radio"], ads = x[, "ads"],
weight = 0, bias = 0, learning.rate = 0.1, iters = 10000)
# model evaluation
train(radio = x[,"radio"], ads = x[, "ads"],
weight = 0, bias = 0, learning.rate = 0.01, iters = 10000)
# model training
train <- function(radio, ads, weight, bias, learning.rate, iters){
cost.history <- numeric()
for(i in 1:length(iters)){
gradient.descent.out <- gradient.descent(radio, ads, weight, bias, learning.rate)
weight <- gradient.descent.out[[1]]
bias <- gradient.descent.out[[2]]
# calculate cost
cost <- cost.function(radio, ads, weight, bias)
cost.history <- c(cost.history, cost)
# Log the progress
if(i%%1 == 0){
print(paste0("iters = ", i, "\t",
"weight = ", weight, "\t",
"bias = ", bias, "\t"))
}
}
return(list(weight, bias, cost.history))
}
# model evaluation
train(radio = x[,"radio"], ads = x[, "ads"],
weight = 0, bias = 0, learning.rate = 0.01, iters = 10000)
# model training
train <- function(radio, ads, weight, bias, learning.rate, iters){
cost.history <- numeric()
for(i in 1:length(iters)){
gradient.descent.out <- gradient.descent(radio, ads, weight, bias, learning.rate)
weight <- gradient.descent.out[[1]]
bias <- gradient.descent.out[[2]]
# calculate cost
cost <- cost.function(radio, ads, weight, bias)
cost.history <- c(cost.history, cost)
# Log the progress
print(paste0("iters = ", i, "\t",
"weight = ", weight, "\t",
"bias = ", bias, "\t"))
}
return(list(weight, bias, cost.history))
}
# model evaluation
train(radio = x[,"radio"], ads = x[, "ads"],
weight = 0, bias = 0, learning.rate = 0.01, iters = 10000)
x[,"radio"]
# model evaluation
train(radio = x[,"radio"], ads = x[, "ads"],
weight = 0.03, bias = 0.00014, learning.rate = 0.01, iters = 10000)
set.seed(1234)
rng <- sample(x = 400, size = 6, replace = TRUE)
print(rng)
?readRDS
k=2
iters <- 1:(4^k)
length(iters)
k=8
iters <- 1:(4^k)
length(iters)
iters <- 1:(4^10)
length(iters)
iters <- 1:(4^12)
length(iters)
iters <- 1:(4^14)
length(iters)
cat
?cat
cat(paste0("time "))
x=1
cat(paste0("time ", x))
# Load required supplementary functions and packages
suppressPackageStartupMessages(library(deSolve))
suppressPackageStartupMessages(library(truncnorm))
suppressPackageStartupMessages(library(doRNG))
suppressPackageStartupMessages(library(doParallel))
suppressPackageStartupMessages(library(foreach))
my_path="/Users/paddy/Documents/DPhil/01-Chargaff/02-simulations/scripts/Main_Simulation/"
ncpu=2
runs=100
muttype="Non_Symmetric"
dist="uniform"
scale.fac=1
sim.evol=FALSE
setwd(my_path)
# source dependencies
source("../../lib/SolveATGC.R")
source("../../lib/InputChecking.R")
source("../../lib/Simulation.R")
# Import calculated mutation rates from trek paper
note.one   <- read.csv("../../data/Raw/Trek-paper-Note-1-mutation-rates.csv",
header = TRUE)
note.two   <- read.csv("../../data/Raw/Trek-paper-Note-2-mutation-rates.csv",
header = TRUE)
note.three <- read.csv("../../data/Raw/Trek-paper-Note-3-mutation-rates.csv",
header = TRUE)
sim.results <- solsym(Acont      = 0.25, # %
Gcont      = 0.25, # %
Ccont      = 0.25, # %
span       = 4.28, # byr
step       = 0.001, # byr
max.runs   = runs, # number of iterations
muttype    = muttype,
dist       = dist,
species    = "NONE",
scale.fac  = scale.fac,
tolerance  = FALSE,
tol.return = "NONE",
sim.evol   = sim.evol,
NCPU       = ncpu,
seed       = 1)
my_path="/Users/paddy/Documents/DPhil/01-Chargaff/02-simulations/scripts/Main_Simulation/"
ncpu=2
runs=100
muttype="Non_Symmetric"
dist="uniform"
scale.fac=1
sim.evol=FALSE
setwd(my_path)
# source dependencies
source("../../lib/SolveATGC.R")
source("../../lib/InputChecking.R")
source("../../lib/Simulation.R")
# Import calculated mutation rates from trek paper
note.one   <- read.csv("../../data/Raw/Trek-paper-Note-1-mutation-rates.csv",
header = TRUE)
note.two   <- read.csv("../../data/Raw/Trek-paper-Note-2-mutation-rates.csv",
header = TRUE)
note.three <- read.csv("../../data/Raw/Trek-paper-Note-3-mutation-rates.csv",
header = TRUE)
sim.results <- solsym(Acont      = 0.25, # %
Gcont      = 0.25, # %
Ccont      = 0.25, # %
span       = 4.28, # byr
step       = 0.001, # byr
max.runs   = runs, # number of iterations
muttype    = muttype,
dist       = dist,
species    = "NONE",
scale.fac  = scale.fac,
tolerance  = FALSE,
tol.return = "NONE",
sim.evol   = sim.evol,
NCPU       = ncpu,
seed       = 1)
suppressPackageStartupMessages(library(dplyr))
# Load required supplementary functions and packages
suppressPackageStartupMessages(library(deSolve))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(truncnorm))
suppressPackageStartupMessages(library(doRNG))
suppressPackageStartupMessages(library(doParallel))
suppressPackageStartupMessages(library(foreach))
# args <- commandArgs(trailingOnly = TRUE)
# my_path <- as.character(args[1])
# ncpu <- as.numeric(args[2])
# runs <- as.numeric(args[3])
# muttype <- as.character(args[4])
# dist <- as.character(args[5])
# scale.fac <- as.numeric(args[6])
# sim.evol <- as.character(args[7])
# sim.evol <- as.logical(sim.evol)
my_path="/Users/paddy/Documents/DPhil/01-Chargaff/02-simulations/scripts/Main_Simulation/"
ncpu=2
runs=100
muttype="Non_Symmetric"
dist="uniform"
scale.fac=1
sim.evol=FALSE
setwd(my_path)
# source dependencies
source("../../lib/SolveATGC.R")
source("../../lib/InputChecking.R")
source("../../lib/Simulation.R")
# Import calculated mutation rates from trek paper
note.one   <- read.csv("../../data/Raw/Trek-paper-Note-1-mutation-rates.csv",
header = TRUE)
note.two   <- read.csv("../../data/Raw/Trek-paper-Note-2-mutation-rates.csv",
header = TRUE)
note.three <- read.csv("../../data/Raw/Trek-paper-Note-3-mutation-rates.csv",
header = TRUE)
sim.results <- solsym(Acont      = 0.25, # %
Gcont      = 0.25, # %
Ccont      = 0.25, # %
span       = 4.28, # byr
step       = 0.001, # byr
max.runs   = runs, # number of iterations
muttype    = muttype,
dist       = dist,
species    = "NONE",
scale.fac  = scale.fac,
tolerance  = FALSE,
tol.return = "NONE",
sim.evol   = sim.evol,
NCPU       = ncpu,
seed       = 1)
sim.resuts
sim.results
readRDS("../../data/Main_Simulation/test.Rdata")
load("../../data/Main_Simulation/test.Rdata")
ls()
load("../../data/Main_Simulation/test.Rdata")
sim.run
solsym(Acont      = 0.25, # %
Gcont      = 0.25, # %
Ccont      = 0.25, # %
span       = 4.28, # byr
step       = 0.001, # byr
max.runs   = runs, # number of iterations
muttype    = muttype,
dist       = dist,
species    = "NONE",
scale.fac  = scale.fac,
tolerance  = FALSE,
tol.return = "NONE",
sim.evol   = sim.evol,
NCPU       = ncpu,
seed       = 1)
load("../../data/Main_Simulation/test.Rdata")
sim.run
